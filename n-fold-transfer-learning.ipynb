{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport glob\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Flatten,GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import MobileNetV2\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport keras\nimport openpyxl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-04T11:41:21.616090Z","iopub.execute_input":"2023-05-04T11:41:21.616470Z","iopub.status.idle":"2023-05-04T11:41:21.624681Z","shell.execute_reply.started":"2023-05-04T11:41:21.616427Z","shell.execute_reply":"2023-05-04T11:41:21.623714Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def transfer_learning_Model(model='VGG16'):\n    # Add a GlobalAveragePooling2D layer and a Dense layer on top of the pre-trained model\n    if model=='VGG16':\n        base_model = VGG16(input_shape=(img_size[0],img_size[0], 3), include_top=False, weights='imagenet')\n        x = Flatten()(base_model.output)\n    elif model=='MobileNetV2':\n        base_model = MobileNetV2(input_shape=(img_size[0],img_size[0], 3),weights='imagenet', include_top=False)\n        x = base_model.output\n        x = GlobalAveragePooling2D()(x)\n    elif model=='InceptionV3':\n        base_model = InceptionV3(input_shape=(img_size[0],img_size[0], 3),weights='imagenet', include_top=False)\n        x = base_model.output\n        x = GlobalAveragePooling2D()(x)\n    elif model=='DenseNet121':\n        base_model = DenseNet121(input_shape=(img_size[0],img_size[0], 3),weights='imagenet', include_top=False)\n        x = base_model.output\n        x = GlobalAveragePooling2D()(x)\n    elif model=='ResNet50':\n        base_model = ResNet50(input_shape=(img_size[0],img_size[0], 3),weights='imagenet', include_top=False)\n        x = base_model.output\n        x = GlobalAveragePooling2D()(x)\n\n    x = Dense(512, activation='relu')(x)\n    x = Dense(NUM_CLASSES, activation='softmax')(x)\n\n    # Freeze the layers in the pre-trained model\n    for layer in base_model.layers:\n        layer.trainable = False\n\n\n    model = Model(inputs=base_model.input, outputs=x)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-04T11:41:22.581069Z","iopub.execute_input":"2023-05-04T11:41:22.581572Z","iopub.status.idle":"2023-05-04T11:41:22.589978Z","shell.execute_reply.started":"2023-05-04T11:41:22.581534Z","shell.execute_reply":"2023-05-04T11:41:22.589046Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Define the path to the two folders containing the image files\nfolder1_path = \"/kaggle/input/fundus-images/Data_Processed_Gray/Diseased/\"\nfolder2_path = \"/kaggle/input/fundus-images/Data_Processed_Gray/Healthy/\"\n\n\n# Define the image size and number of channels\nimg_size = (224, 224)\nnum_channels = 3\nNUM_CLASSES=2\nBATCH_SIZE=32\nEPOCHS=1\n\nmodel_name='VGG16'\n\nn_splits = 2","metadata":{"execution":{"iopub.status.busy":"2023-05-04T11:41:23.581966Z","iopub.execute_input":"2023-05-04T11:41:23.582624Z","iopub.status.idle":"2023-05-04T11:41:23.588095Z","shell.execute_reply.started":"2023-05-04T11:41:23.582585Z","shell.execute_reply":"2023-05-04T11:41:23.586979Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Initialize lists to store image data and labels\nX = []\ny = []\n\n# Load image files from folder1 and append to X and y lists\nfor filepath in glob.glob(folder1_path + \"*.jpg\"):\n    img = cv2.imread(filepath)\n    img = cv2.resize(img, img_size)\n    X.append(img/255.)\n    y.append(0) # Set label to 0 for images in folder1\n\n# Load image files from folder2 and append to X and y lists\nfor filepath in glob.glob(folder2_path + \"*.jpg\"):\n    img = cv2.imread(filepath)\n    img = cv2.resize(img, img_size)\n    X.append(img/255.)\n    y.append(1) # Set label to 1 for images in folder2\n\n# Convert X and y to numpy arrays\nX = np.array(X)\ny = np.array(y)\n\nprint('Loading Complete')\n# Define the VGG16 model\nmodel = transfer_learning_Model(model=model_name)\n\n\n# Define the data augmentation generator\ndata_augmentation = ImageDataGenerator(\n        rotation_range=10,\n#         width_shift_range=0.1,\n#         height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest'\n)\n\n\n# Initialize lists to store evaluation metrics for each fold\naccuracies = []\nprecisions = []\nf1scores = []\nrecalls = []\n\n# Initialize a KFold object\nkf = KFold(n_splits=n_splits, shuffle=True)\n\n# Perform cross-validation\nfold = 1\nfor train_index, test_index in kf.split(X):\n    print(f\"Fold {fold}\")\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    # Train your model on the training data\n    optimizer = Adam(lr=0.0001)\n    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    # Calculate class weights based on the training data\n    class_weights = {0: len(y_train[y_train== 0])/len(y_train), \n                     1: len(y_train[y_train == 1])/len(y_train)}\n    \n    print(class_weights)\n    # Create a checkpoint to save the best model weights\n    checkpoint_path = f'fold{fold}-{model_name}-best.h5'\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1\n    )\n    \n    # Fit the model with data augmentation and the checkpoint\n    history = model.fit(\n        data_augmentation.flow(X_train, y_train, batch_size=BATCH_SIZE),\n        steps_per_epoch=len(X_train) // BATCH_SIZE,\n        epochs=EPOCHS,\n        class_weight=class_weights,\n        validation_data=(X_test, y_test),\n        callbacks=[checkpoint]\n    )\n    \n    model = keras.models.load_model(f'fold{fold}-{model_name}-best.h5')\n\n    # Make predictions on the test data using the trained model\n    y_pred = model.predict(X_test)\n\n    # Evaluate the predictions\n    y_pred=np.argmax(y_pred,axis=1)\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted')\n    f1score = f1_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n\n    # Print the evaluation metrics\n    print(f\"Accuracy: {accuracy}\")\n    print(f\"Precision: {precision}\")\n    print(f\"F1 Score: {f1score}\")\n    print(f\"Recall: {recall}\")\n\n    # Append the evaluation metrics to the lists\n    accuracies.append(accuracy)\n    precisions.append(precision)\n    f1scores.append(f1score)\n    recalls.append(recall)\n    print('----------------------------------------------')\n    print(f'fold-{fold}-completed')\n    print('----------------------------------------------')\n    fold=fold+1\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-04T11:43:53.700210Z","iopub.execute_input":"2023-05-04T11:43:53.700578Z","iopub.status.idle":"2023-05-04T11:44:16.359270Z","shell.execute_reply.started":"2023-05-04T11:43:53.700545Z","shell.execute_reply":"2023-05-04T11:44:16.358219Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Loading Complete\nFold 1\n{0: 0.7397260273972602, 1: 0.2602739726027397}\n4/4 [==============================] - ETA: 0s - loss: 3.0494 - accuracy: 0.6667\nEpoch 1: val_accuracy improved from -inf to 0.71233, saving model to fold1-VGG16-best.h5\n4/4 [==============================] - 3s 680ms/step - loss: 3.0494 - accuracy: 0.6667 - val_loss: 13.8342 - val_accuracy: 0.7123\n5/5 [==============================] - 0s 62ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.7123287671232876\nPrecision: 0.507412272471383\nF1 Score: 0.5926575342465753\nRecall: 0.7123287671232876\n----------------------------------------------\nfold-1-completed\n----------------------------------------------\nFold 2\n{0: 0.7123287671232876, 1: 0.2876712328767123}\n4/4 [==============================] - ETA: 0s - loss: 3.6506 - accuracy: 0.5000\nEpoch 1: val_accuracy improved from -inf to 0.73973, saving model to fold2-VGG16-best.h5\n4/4 [==============================] - 3s 608ms/step - loss: 3.6506 - accuracy: 0.5000 - val_loss: 1.0439 - val_accuracy: 0.7397\n5/5 [==============================] - 0s 66ms/step\nAccuracy: 0.7397260273972602\nPrecision: 0.5471945956089321\nF1 Score: 0.6290583540071191\nRecall: 0.7397260273972602\n----------------------------------------------\nfold-2-completed\n----------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# Write the evaluation metrics to a text file\nwith open(f'evaluation_metrics_Res_{model_name}.txt', 'w') as f:\n    f.write(f\"Accuracy: {accuracies}\\n\")\n    f.write(f\"Precision: {precisions}\\n\")\n    f.write(f\"F1 Score: {f1scores}\\n\")\n    f.write(f\"Recall: {recalls}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-05-04T11:44:16.361482Z","iopub.execute_input":"2023-05-04T11:44:16.362615Z","iopub.status.idle":"2023-05-04T11:44:16.368595Z","shell.execute_reply.started":"2023-05-04T11:44:16.362576Z","shell.execute_reply":"2023-05-04T11:44:16.367543Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Create a new workbook\nworkbook = openpyxl.Workbook()\n\n# Create a new sheet\nsheet = workbook.active\n\n# Write the header row\nheader_row = [\"Fold\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\nsheet.append(header_row)\n\n# Write the evaluation metrics for each fold\nfor fold in range(fold):\n    row = [fold+1, accuracies[fold], precisions[fold], recalls[fold], f1scores[fold]]\n    sheet.append(row)\n\n# Save the workbook\nworkbook.save(f\"evaluation_{model_name}.xlsx\")\nworkbook.close()","metadata":{"execution":{"iopub.status.busy":"2023-05-04T11:44:37.184899Z","iopub.execute_input":"2023-05-04T11:44:37.185270Z","iopub.status.idle":"2023-05-04T11:44:37.200254Z","shell.execute_reply.started":"2023-05-04T11:44:37.185240Z","shell.execute_reply":"2023-05-04T11:44:37.199323Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}